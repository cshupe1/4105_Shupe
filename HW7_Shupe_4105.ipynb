{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMH6I40GB7pwN+HQ0Tto7Ai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cshupe1/4105_Shupe/blob/main/HW7_Shupe_4105.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1A"
      ],
      "metadata": {
        "id": "UzME9kTLYJlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwTZhKHaYDxn",
        "outputId": "d714bae8-dc3b-42bf-a857-354677d6baad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 19s 6ms/step - loss: 1.4773 - accuracy: 0.4597 - val_loss: 1.1876 - val_accuracy: 0.5704\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0865 - accuracy: 0.6153 - val_loss: 1.0003 - val_accuracy: 0.6468\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9146 - accuracy: 0.6759 - val_loss: 0.9254 - val_accuracy: 0.6759\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8135 - accuracy: 0.7137 - val_loss: 0.8943 - val_accuracy: 0.6906\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7329 - accuracy: 0.7434 - val_loss: 0.8459 - val_accuracy: 0.7087\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6620 - accuracy: 0.7668 - val_loss: 0.8862 - val_accuracy: 0.6986\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6051 - accuracy: 0.7871 - val_loss: 0.8542 - val_accuracy: 0.7125\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5447 - accuracy: 0.8074 - val_loss: 0.8666 - val_accuracy: 0.7148\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4895 - accuracy: 0.8271 - val_loss: 0.9434 - val_accuracy: 0.7021\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4459 - accuracy: 0.8425 - val_loss: 0.9421 - val_accuracy: 0.7097\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3965 - accuracy: 0.8602 - val_loss: 1.0256 - val_accuracy: 0.7066\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3546 - accuracy: 0.8749 - val_loss: 1.0640 - val_accuracy: 0.7074\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3164 - accuracy: 0.8874 - val_loss: 1.1094 - val_accuracy: 0.7150\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2920 - accuracy: 0.8952 - val_loss: 1.1673 - val_accuracy: 0.7104\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2526 - accuracy: 0.9102 - val_loss: 1.2739 - val_accuracy: 0.7017\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2325 - accuracy: 0.9176 - val_loss: 1.3532 - val_accuracy: 0.7084\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2140 - accuracy: 0.9249 - val_loss: 1.4032 - val_accuracy: 0.7101\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1872 - accuracy: 0.9332 - val_loss: 1.4699 - val_accuracy: 0.7072\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1820 - accuracy: 0.9341 - val_loss: 1.6397 - val_accuracy: 0.6906\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1709 - accuracy: 0.9388 - val_loss: 1.6751 - val_accuracy: 0.7039\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1544 - accuracy: 0.9459 - val_loss: 1.7719 - val_accuracy: 0.6923\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1486 - accuracy: 0.9479 - val_loss: 1.8270 - val_accuracy: 0.7008\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1474 - accuracy: 0.9479 - val_loss: 1.8315 - val_accuracy: 0.7006\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1286 - accuracy: 0.9541 - val_loss: 2.0686 - val_accuracy: 0.6861\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1351 - accuracy: 0.9525 - val_loss: 2.0916 - val_accuracy: 0.6913\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1310 - accuracy: 0.9543 - val_loss: 2.4079 - val_accuracy: 0.6684\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1289 - accuracy: 0.9555 - val_loss: 2.1467 - val_accuracy: 0.6897\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1207 - accuracy: 0.9599 - val_loss: 2.3231 - val_accuracy: 0.6711\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1182 - accuracy: 0.9589 - val_loss: 2.1906 - val_accuracy: 0.6892\n",
            "Epoch 30/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1155 - accuracy: 0.9605 - val_loss: 2.2461 - val_accuracy: 0.6991\n",
            "Epoch 31/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1179 - accuracy: 0.9599 - val_loss: 2.3649 - val_accuracy: 0.6927\n",
            "Epoch 32/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1125 - accuracy: 0.9619 - val_loss: 2.3414 - val_accuracy: 0.6903\n",
            "Epoch 33/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1102 - accuracy: 0.9631 - val_loss: 2.4803 - val_accuracy: 0.6981\n",
            "Epoch 34/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1041 - accuracy: 0.9657 - val_loss: 2.4672 - val_accuracy: 0.6906\n",
            "Epoch 35/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1038 - accuracy: 0.9656 - val_loss: 2.6254 - val_accuracy: 0.6902\n",
            "Epoch 36/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1072 - accuracy: 0.9647 - val_loss: 2.6451 - val_accuracy: 0.6853\n",
            "Epoch 37/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0967 - accuracy: 0.9681 - val_loss: 2.7390 - val_accuracy: 0.6851\n",
            "Epoch 38/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1006 - accuracy: 0.9663 - val_loss: 2.8036 - val_accuracy: 0.6896\n",
            "Epoch 39/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1067 - accuracy: 0.9658 - val_loss: 2.8238 - val_accuracy: 0.6891\n",
            "Epoch 40/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0897 - accuracy: 0.9709 - val_loss: 2.8457 - val_accuracy: 0.6880\n",
            "Epoch 41/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1030 - accuracy: 0.9668 - val_loss: 2.6939 - val_accuracy: 0.6985\n",
            "Epoch 42/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0992 - accuracy: 0.9680 - val_loss: 2.6870 - val_accuracy: 0.6980\n",
            "Epoch 43/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0966 - accuracy: 0.9699 - val_loss: 2.7714 - val_accuracy: 0.6954\n",
            "Epoch 44/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0861 - accuracy: 0.9716 - val_loss: 2.9952 - val_accuracy: 0.6839\n",
            "Epoch 45/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0972 - accuracy: 0.9696 - val_loss: 3.0395 - val_accuracy: 0.6893\n",
            "Epoch 46/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0932 - accuracy: 0.9694 - val_loss: 2.8854 - val_accuracy: 0.6917\n",
            "Epoch 47/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0899 - accuracy: 0.9720 - val_loss: 3.0181 - val_accuracy: 0.6890\n",
            "Epoch 48/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0875 - accuracy: 0.9725 - val_loss: 3.0919 - val_accuracy: 0.6885\n",
            "Epoch 49/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0885 - accuracy: 0.9721 - val_loss: 3.2364 - val_accuracy: 0.6860\n",
            "Epoch 50/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0877 - accuracy: 0.9727 - val_loss: 3.0987 - val_accuracy: 0.6929\n",
            "Epoch 51/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0911 - accuracy: 0.9720 - val_loss: 3.1307 - val_accuracy: 0.6897\n",
            "Epoch 52/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0861 - accuracy: 0.9735 - val_loss: 3.1594 - val_accuracy: 0.6880\n",
            "Epoch 53/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0876 - accuracy: 0.9741 - val_loss: 3.1135 - val_accuracy: 0.6818\n",
            "Epoch 54/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0931 - accuracy: 0.9710 - val_loss: 3.1972 - val_accuracy: 0.6865\n",
            "Epoch 55/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0901 - accuracy: 0.9734 - val_loss: 3.2189 - val_accuracy: 0.6845\n",
            "Epoch 56/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0804 - accuracy: 0.9758 - val_loss: 3.1191 - val_accuracy: 0.6966\n",
            "Epoch 57/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0838 - accuracy: 0.9746 - val_loss: 3.3020 - val_accuracy: 0.6856\n",
            "Epoch 58/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0924 - accuracy: 0.9725 - val_loss: 3.1550 - val_accuracy: 0.6926\n",
            "Epoch 59/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0803 - accuracy: 0.9757 - val_loss: 3.2739 - val_accuracy: 0.6896\n",
            "Epoch 60/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0797 - accuracy: 0.9760 - val_loss: 3.2984 - val_accuracy: 0.6928\n",
            "Epoch 61/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0890 - accuracy: 0.9740 - val_loss: 3.2985 - val_accuracy: 0.6878\n",
            "Epoch 62/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0765 - accuracy: 0.9777 - val_loss: 3.3163 - val_accuracy: 0.6933\n",
            "Epoch 63/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0773 - accuracy: 0.9762 - val_loss: 3.5598 - val_accuracy: 0.6866\n",
            "Epoch 64/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0786 - accuracy: 0.9760 - val_loss: 3.4860 - val_accuracy: 0.6896\n",
            "Epoch 65/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0720 - accuracy: 0.9783 - val_loss: 3.5998 - val_accuracy: 0.6792\n",
            "Epoch 66/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0864 - accuracy: 0.9752 - val_loss: 3.3935 - val_accuracy: 0.6839\n",
            "Epoch 67/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0671 - accuracy: 0.9799 - val_loss: 3.6500 - val_accuracy: 0.6805\n",
            "Epoch 68/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0817 - accuracy: 0.9759 - val_loss: 3.6141 - val_accuracy: 0.6856\n",
            "Epoch 69/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 3.6380 - val_accuracy: 0.6913\n",
            "Epoch 70/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0754 - accuracy: 0.9773 - val_loss: 3.6565 - val_accuracy: 0.6904\n",
            "Epoch 71/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0786 - accuracy: 0.9770 - val_loss: 3.5064 - val_accuracy: 0.6928\n",
            "Epoch 72/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0672 - accuracy: 0.9794 - val_loss: 3.7709 - val_accuracy: 0.6868\n",
            "Epoch 73/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0763 - accuracy: 0.9786 - val_loss: 3.8079 - val_accuracy: 0.6822\n",
            "Epoch 74/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0779 - accuracy: 0.9779 - val_loss: 3.8102 - val_accuracy: 0.6834\n",
            "Epoch 75/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0748 - accuracy: 0.9787 - val_loss: 3.8490 - val_accuracy: 0.6798\n",
            "Epoch 76/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0768 - accuracy: 0.9780 - val_loss: 3.8965 - val_accuracy: 0.6850\n",
            "Epoch 77/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0611 - accuracy: 0.9814 - val_loss: 3.9491 - val_accuracy: 0.6813\n",
            "Epoch 78/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0738 - accuracy: 0.9789 - val_loss: 3.8747 - val_accuracy: 0.6857\n",
            "Epoch 79/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0797 - accuracy: 0.9787 - val_loss: 3.8904 - val_accuracy: 0.6924\n",
            "Epoch 80/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0694 - accuracy: 0.9799 - val_loss: 3.8939 - val_accuracy: 0.6874\n",
            "Epoch 81/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0782 - accuracy: 0.9789 - val_loss: 3.8734 - val_accuracy: 0.6831\n",
            "Epoch 82/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0681 - accuracy: 0.9798 - val_loss: 4.1904 - val_accuracy: 0.6855\n",
            "Epoch 83/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0744 - accuracy: 0.9791 - val_loss: 4.0162 - val_accuracy: 0.6840\n",
            "Epoch 84/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0734 - accuracy: 0.9792 - val_loss: 4.0016 - val_accuracy: 0.6804\n",
            "Epoch 85/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0661 - accuracy: 0.9812 - val_loss: 4.1531 - val_accuracy: 0.6924\n",
            "Epoch 86/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0786 - accuracy: 0.9795 - val_loss: 4.1596 - val_accuracy: 0.6857\n",
            "Epoch 87/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0728 - accuracy: 0.9797 - val_loss: 4.1677 - val_accuracy: 0.6755\n",
            "Epoch 88/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0800 - accuracy: 0.9786 - val_loss: 4.1244 - val_accuracy: 0.6837\n",
            "Epoch 89/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0627 - accuracy: 0.9825 - val_loss: 4.0669 - val_accuracy: 0.6905\n",
            "Epoch 90/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0808 - accuracy: 0.9793 - val_loss: 4.2200 - val_accuracy: 0.6910\n",
            "Epoch 91/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0658 - accuracy: 0.9816 - val_loss: 4.1617 - val_accuracy: 0.6932\n",
            "Epoch 92/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0745 - accuracy: 0.9798 - val_loss: 4.3241 - val_accuracy: 0.6847\n",
            "Epoch 93/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0745 - accuracy: 0.9803 - val_loss: 4.3115 - val_accuracy: 0.6827\n",
            "Epoch 94/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0713 - accuracy: 0.9813 - val_loss: 4.2983 - val_accuracy: 0.6848\n",
            "Epoch 95/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0780 - accuracy: 0.9792 - val_loss: 4.3225 - val_accuracy: 0.6789\n",
            "Epoch 96/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0653 - accuracy: 0.9821 - val_loss: 4.5177 - val_accuracy: 0.6829\n",
            "Epoch 97/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0714 - accuracy: 0.9807 - val_loss: 4.6208 - val_accuracy: 0.6890\n",
            "Epoch 98/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0698 - accuracy: 0.9820 - val_loss: 4.6395 - val_accuracy: 0.6785\n",
            "Epoch 99/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0736 - accuracy: 0.9807 - val_loss: 4.4772 - val_accuracy: 0.6912\n",
            "Epoch 100/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0699 - accuracy: 0.9810 - val_loss: 4.2737 - val_accuracy: 0.6903\n",
            "Epoch 101/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0735 - accuracy: 0.9802 - val_loss: 4.3832 - val_accuracy: 0.6967\n",
            "Epoch 102/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0712 - accuracy: 0.9820 - val_loss: 4.3451 - val_accuracy: 0.6954\n",
            "Epoch 103/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0686 - accuracy: 0.9824 - val_loss: 4.6653 - val_accuracy: 0.6801\n",
            "Epoch 104/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0697 - accuracy: 0.9825 - val_loss: 4.5329 - val_accuracy: 0.6798\n",
            "Epoch 105/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0608 - accuracy: 0.9838 - val_loss: 4.7024 - val_accuracy: 0.6865\n",
            "Epoch 106/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0830 - accuracy: 0.9799 - val_loss: 4.6176 - val_accuracy: 0.6928\n",
            "Epoch 107/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0669 - accuracy: 0.9828 - val_loss: 4.6521 - val_accuracy: 0.6831\n",
            "Epoch 108/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0630 - accuracy: 0.9835 - val_loss: 4.7358 - val_accuracy: 0.6793\n",
            "Epoch 109/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0767 - accuracy: 0.9807 - val_loss: 4.8913 - val_accuracy: 0.6835\n",
            "Epoch 110/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0751 - accuracy: 0.9810 - val_loss: 4.6983 - val_accuracy: 0.6801\n",
            "Epoch 111/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0694 - accuracy: 0.9825 - val_loss: 5.0561 - val_accuracy: 0.6827\n",
            "Epoch 112/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0763 - accuracy: 0.9813 - val_loss: 5.3082 - val_accuracy: 0.6776\n",
            "Epoch 113/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0702 - accuracy: 0.9819 - val_loss: 4.9757 - val_accuracy: 0.6827\n",
            "Epoch 114/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0613 - accuracy: 0.9843 - val_loss: 5.3113 - val_accuracy: 0.6745\n",
            "Epoch 115/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0751 - accuracy: 0.9826 - val_loss: 4.7475 - val_accuracy: 0.6863\n",
            "Epoch 116/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0748 - accuracy: 0.9819 - val_loss: 4.8081 - val_accuracy: 0.6829\n",
            "Epoch 117/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0661 - accuracy: 0.9837 - val_loss: 5.3584 - val_accuracy: 0.6827\n",
            "Epoch 118/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0654 - accuracy: 0.9834 - val_loss: 5.2025 - val_accuracy: 0.6823\n",
            "Epoch 119/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0767 - accuracy: 0.9818 - val_loss: 5.1617 - val_accuracy: 0.6790\n",
            "Epoch 120/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0680 - accuracy: 0.9825 - val_loss: 5.2368 - val_accuracy: 0.6860\n",
            "Epoch 121/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0683 - accuracy: 0.9836 - val_loss: 5.3926 - val_accuracy: 0.6751\n",
            "Epoch 122/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0761 - accuracy: 0.9823 - val_loss: 5.1384 - val_accuracy: 0.6834\n",
            "Epoch 123/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0717 - accuracy: 0.9828 - val_loss: 5.0331 - val_accuracy: 0.6869\n",
            "Epoch 124/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0643 - accuracy: 0.9839 - val_loss: 5.4095 - val_accuracy: 0.6822\n",
            "Epoch 125/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0691 - accuracy: 0.9840 - val_loss: 5.3128 - val_accuracy: 0.6844\n",
            "Epoch 126/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0734 - accuracy: 0.9824 - val_loss: 5.4010 - val_accuracy: 0.6887\n",
            "Epoch 127/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0795 - accuracy: 0.9821 - val_loss: 5.3776 - val_accuracy: 0.6738\n",
            "Epoch 128/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0642 - accuracy: 0.9840 - val_loss: 5.3526 - val_accuracy: 0.6922\n",
            "Epoch 129/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0788 - accuracy: 0.9823 - val_loss: 5.3286 - val_accuracy: 0.6861\n",
            "Epoch 130/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0705 - accuracy: 0.9840 - val_loss: 5.4717 - val_accuracy: 0.6802\n",
            "Epoch 131/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0664 - accuracy: 0.9842 - val_loss: 5.4902 - val_accuracy: 0.6871\n",
            "Epoch 132/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0647 - accuracy: 0.9844 - val_loss: 5.5220 - val_accuracy: 0.6780\n",
            "Epoch 133/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0674 - accuracy: 0.9845 - val_loss: 5.7378 - val_accuracy: 0.6876\n",
            "Epoch 134/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0808 - accuracy: 0.9820 - val_loss: 5.5823 - val_accuracy: 0.6847\n",
            "Epoch 135/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0724 - accuracy: 0.9842 - val_loss: 5.4421 - val_accuracy: 0.6890\n",
            "Epoch 136/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0662 - accuracy: 0.9846 - val_loss: 5.7805 - val_accuracy: 0.6827\n",
            "Epoch 137/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0696 - accuracy: 0.9839 - val_loss: 5.7849 - val_accuracy: 0.6877\n",
            "Epoch 138/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0832 - accuracy: 0.9822 - val_loss: 5.5952 - val_accuracy: 0.6818\n",
            "Epoch 139/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0578 - accuracy: 0.9857 - val_loss: 6.0536 - val_accuracy: 0.6831\n",
            "Epoch 140/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9831 - val_loss: 5.9226 - val_accuracy: 0.6855\n",
            "Epoch 141/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0795 - accuracy: 0.9834 - val_loss: 5.6959 - val_accuracy: 0.6838\n",
            "Epoch 142/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0601 - accuracy: 0.9853 - val_loss: 5.8209 - val_accuracy: 0.6840\n",
            "Epoch 143/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0714 - accuracy: 0.9840 - val_loss: 5.9625 - val_accuracy: 0.6897\n",
            "Epoch 144/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0690 - accuracy: 0.9850 - val_loss: 6.0137 - val_accuracy: 0.6839\n",
            "Epoch 145/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0713 - accuracy: 0.9839 - val_loss: 5.9866 - val_accuracy: 0.6762\n",
            "Epoch 146/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0724 - accuracy: 0.9848 - val_loss: 5.7675 - val_accuracy: 0.6939\n",
            "Epoch 147/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0745 - accuracy: 0.9840 - val_loss: 6.1526 - val_accuracy: 0.6819\n",
            "Epoch 148/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0737 - accuracy: 0.9839 - val_loss: 6.1576 - val_accuracy: 0.6803\n",
            "Epoch 149/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0701 - accuracy: 0.9850 - val_loss: 5.8821 - val_accuracy: 0.6818\n",
            "Epoch 150/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0725 - accuracy: 0.9840 - val_loss: 6.2046 - val_accuracy: 0.6850\n",
            "Epoch 151/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0673 - accuracy: 0.9847 - val_loss: 6.2607 - val_accuracy: 0.6840\n",
            "Epoch 152/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0732 - accuracy: 0.9848 - val_loss: 6.4478 - val_accuracy: 0.6843\n",
            "Epoch 153/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0775 - accuracy: 0.9844 - val_loss: 6.1536 - val_accuracy: 0.6866\n",
            "Epoch 154/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0760 - accuracy: 0.9842 - val_loss: 6.2079 - val_accuracy: 0.6869\n",
            "Epoch 155/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0743 - accuracy: 0.9841 - val_loss: 6.3533 - val_accuracy: 0.6760\n",
            "Epoch 156/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0695 - accuracy: 0.9853 - val_loss: 6.6951 - val_accuracy: 0.6894\n",
            "Epoch 157/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0654 - accuracy: 0.9862 - val_loss: 6.3888 - val_accuracy: 0.6861\n",
            "Epoch 158/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0760 - accuracy: 0.9837 - val_loss: 6.5328 - val_accuracy: 0.6844\n",
            "Epoch 159/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0727 - accuracy: 0.9849 - val_loss: 6.4909 - val_accuracy: 0.6781\n",
            "Epoch 160/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0718 - accuracy: 0.9845 - val_loss: 6.8948 - val_accuracy: 0.6827\n",
            "Epoch 161/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0794 - accuracy: 0.9846 - val_loss: 6.8238 - val_accuracy: 0.6818\n",
            "Epoch 162/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0652 - accuracy: 0.9868 - val_loss: 6.5996 - val_accuracy: 0.6901\n",
            "Epoch 163/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0765 - accuracy: 0.9848 - val_loss: 6.8426 - val_accuracy: 0.6891\n",
            "Epoch 164/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0664 - accuracy: 0.9859 - val_loss: 6.9585 - val_accuracy: 0.6859\n",
            "Epoch 165/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0800 - accuracy: 0.9851 - val_loss: 6.7186 - val_accuracy: 0.6786\n",
            "Epoch 166/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0682 - accuracy: 0.9856 - val_loss: 7.1461 - val_accuracy: 0.6897\n",
            "Epoch 167/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0823 - accuracy: 0.9844 - val_loss: 6.6812 - val_accuracy: 0.6810\n",
            "Epoch 168/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0789 - accuracy: 0.9843 - val_loss: 6.6484 - val_accuracy: 0.6913\n",
            "Epoch 169/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0663 - accuracy: 0.9863 - val_loss: 6.9205 - val_accuracy: 0.6802\n",
            "Epoch 170/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0599 - accuracy: 0.9874 - val_loss: 6.9969 - val_accuracy: 0.6853\n",
            "Epoch 171/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0750 - accuracy: 0.9856 - val_loss: 6.9111 - val_accuracy: 0.6821\n",
            "Epoch 172/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0749 - accuracy: 0.9849 - val_loss: 7.2147 - val_accuracy: 0.6847\n",
            "Epoch 173/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0779 - accuracy: 0.9854 - val_loss: 7.1534 - val_accuracy: 0.6778\n",
            "Epoch 174/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0693 - accuracy: 0.9865 - val_loss: 7.6064 - val_accuracy: 0.6697\n",
            "Epoch 175/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0747 - accuracy: 0.9857 - val_loss: 7.6451 - val_accuracy: 0.6812\n",
            "Epoch 176/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0845 - accuracy: 0.9842 - val_loss: 7.2643 - val_accuracy: 0.6807\n",
            "Epoch 177/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0720 - accuracy: 0.9862 - val_loss: 7.4651 - val_accuracy: 0.6854\n",
            "Epoch 178/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0725 - accuracy: 0.9861 - val_loss: 7.1975 - val_accuracy: 0.6842\n",
            "Epoch 179/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0650 - accuracy: 0.9868 - val_loss: 7.8284 - val_accuracy: 0.6832\n",
            "Epoch 180/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0698 - accuracy: 0.9861 - val_loss: 7.5720 - val_accuracy: 0.6799\n",
            "Epoch 181/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0786 - accuracy: 0.9844 - val_loss: 7.7473 - val_accuracy: 0.6785\n",
            "Epoch 182/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0687 - accuracy: 0.9863 - val_loss: 7.4345 - val_accuracy: 0.6874\n",
            "Epoch 183/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0804 - accuracy: 0.9859 - val_loss: 7.8862 - val_accuracy: 0.6840\n",
            "Epoch 184/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0836 - accuracy: 0.9852 - val_loss: 7.6128 - val_accuracy: 0.6854\n",
            "Epoch 185/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0743 - accuracy: 0.9865 - val_loss: 7.9766 - val_accuracy: 0.6772\n",
            "Epoch 186/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0660 - accuracy: 0.9872 - val_loss: 7.7612 - val_accuracy: 0.6787\n",
            "Epoch 187/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0776 - accuracy: 0.9859 - val_loss: 7.9706 - val_accuracy: 0.6820\n",
            "Epoch 188/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0809 - accuracy: 0.9860 - val_loss: 8.1417 - val_accuracy: 0.6744\n",
            "Epoch 189/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0750 - accuracy: 0.9861 - val_loss: 8.0690 - val_accuracy: 0.6816\n",
            "Epoch 190/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0884 - accuracy: 0.9849 - val_loss: 8.0487 - val_accuracy: 0.6816\n",
            "Epoch 191/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0743 - accuracy: 0.9868 - val_loss: 7.8529 - val_accuracy: 0.6850\n",
            "Epoch 192/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0749 - accuracy: 0.9855 - val_loss: 8.1134 - val_accuracy: 0.6891\n",
            "Epoch 193/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0838 - accuracy: 0.9858 - val_loss: 7.9381 - val_accuracy: 0.6825\n",
            "Epoch 194/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0874 - accuracy: 0.9853 - val_loss: 7.9699 - val_accuracy: 0.6854\n",
            "Epoch 195/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0742 - accuracy: 0.9858 - val_loss: 8.0565 - val_accuracy: 0.6827\n",
            "Epoch 196/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0692 - accuracy: 0.9880 - val_loss: 8.3936 - val_accuracy: 0.6797\n",
            "Epoch 197/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0739 - accuracy: 0.9863 - val_loss: 8.0773 - val_accuracy: 0.6787\n",
            "Epoch 198/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0763 - accuracy: 0.9862 - val_loss: 8.2795 - val_accuracy: 0.6810\n",
            "Epoch 199/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0867 - accuracy: 0.9853 - val_loss: 8.4694 - val_accuracy: 0.6772\n",
            "Epoch 200/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0807 - accuracy: 0.9869 - val_loss: 8.2119 - val_accuracy: 0.6819\n",
            "Epoch 201/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0799 - accuracy: 0.9865 - val_loss: 8.5473 - val_accuracy: 0.6770\n",
            "Epoch 202/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0701 - accuracy: 0.9874 - val_loss: 8.4769 - val_accuracy: 0.6786\n",
            "Epoch 203/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0673 - accuracy: 0.9884 - val_loss: 8.5323 - val_accuracy: 0.6791\n",
            "Epoch 204/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0795 - accuracy: 0.9873 - val_loss: 8.5629 - val_accuracy: 0.6796\n",
            "Epoch 205/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0887 - accuracy: 0.9848 - val_loss: 8.6876 - val_accuracy: 0.6754\n",
            "Epoch 206/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0848 - accuracy: 0.9866 - val_loss: 8.8335 - val_accuracy: 0.6806\n",
            "Epoch 207/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0796 - accuracy: 0.9872 - val_loss: 8.8785 - val_accuracy: 0.6818\n",
            "Epoch 208/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0747 - accuracy: 0.9870 - val_loss: 9.2971 - val_accuracy: 0.6740\n",
            "Epoch 209/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0842 - accuracy: 0.9866 - val_loss: 8.9052 - val_accuracy: 0.6865\n",
            "Epoch 210/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0845 - accuracy: 0.9867 - val_loss: 8.9554 - val_accuracy: 0.6828\n",
            "Epoch 211/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0806 - accuracy: 0.9865 - val_loss: 9.2900 - val_accuracy: 0.6850\n",
            "Epoch 212/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0752 - accuracy: 0.9873 - val_loss: 9.0861 - val_accuracy: 0.6810\n",
            "Epoch 213/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0749 - accuracy: 0.9872 - val_loss: 9.2203 - val_accuracy: 0.6828\n",
            "Epoch 214/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0848 - accuracy: 0.9857 - val_loss: 9.4354 - val_accuracy: 0.6705\n",
            "Epoch 215/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0836 - accuracy: 0.9871 - val_loss: 9.1843 - val_accuracy: 0.6802\n",
            "Epoch 216/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0816 - accuracy: 0.9871 - val_loss: 9.4605 - val_accuracy: 0.6805\n",
            "Epoch 217/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0963 - accuracy: 0.9856 - val_loss: 9.3652 - val_accuracy: 0.6812\n",
            "Epoch 218/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0665 - accuracy: 0.9893 - val_loss: 9.4707 - val_accuracy: 0.6816\n",
            "Epoch 219/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0889 - accuracy: 0.9860 - val_loss: 9.6607 - val_accuracy: 0.6759\n",
            "Epoch 220/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0747 - accuracy: 0.9883 - val_loss: 9.2003 - val_accuracy: 0.6832\n",
            "Epoch 221/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0843 - accuracy: 0.9860 - val_loss: 9.8972 - val_accuracy: 0.6766\n",
            "Epoch 222/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0928 - accuracy: 0.9866 - val_loss: 9.5886 - val_accuracy: 0.6865\n",
            "Epoch 223/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0778 - accuracy: 0.9881 - val_loss: 9.5451 - val_accuracy: 0.6892\n",
            "Epoch 224/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0865 - accuracy: 0.9869 - val_loss: 9.6011 - val_accuracy: 0.6807\n",
            "Epoch 225/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0877 - accuracy: 0.9870 - val_loss: 10.0572 - val_accuracy: 0.6847\n",
            "Epoch 226/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0736 - accuracy: 0.9887 - val_loss: 10.1836 - val_accuracy: 0.6770\n",
            "Epoch 227/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0951 - accuracy: 0.9863 - val_loss: 10.0477 - val_accuracy: 0.6763\n",
            "Epoch 228/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0825 - accuracy: 0.9875 - val_loss: 9.8224 - val_accuracy: 0.6795\n",
            "Epoch 229/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0843 - accuracy: 0.9877 - val_loss: 9.5164 - val_accuracy: 0.6808\n",
            "Epoch 230/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0717 - accuracy: 0.9886 - val_loss: 10.1542 - val_accuracy: 0.6758\n",
            "Epoch 231/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0887 - accuracy: 0.9871 - val_loss: 9.7252 - val_accuracy: 0.6825\n",
            "Epoch 232/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0915 - accuracy: 0.9867 - val_loss: 10.1947 - val_accuracy: 0.6781\n",
            "Epoch 233/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0762 - accuracy: 0.9885 - val_loss: 9.8402 - val_accuracy: 0.6787\n",
            "Epoch 234/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0844 - accuracy: 0.9875 - val_loss: 9.9676 - val_accuracy: 0.6850\n",
            "Epoch 235/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0909 - accuracy: 0.9870 - val_loss: 10.1974 - val_accuracy: 0.6855\n",
            "Epoch 236/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0771 - accuracy: 0.9884 - val_loss: 10.1340 - val_accuracy: 0.6801\n",
            "Epoch 237/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0834 - accuracy: 0.9877 - val_loss: 10.2929 - val_accuracy: 0.6857\n",
            "Epoch 238/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0905 - accuracy: 0.9870 - val_loss: 10.5802 - val_accuracy: 0.6796\n",
            "Epoch 239/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0805 - accuracy: 0.9887 - val_loss: 10.6442 - val_accuracy: 0.6821\n",
            "Epoch 240/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0804 - accuracy: 0.9881 - val_loss: 10.6244 - val_accuracy: 0.6825\n",
            "Epoch 241/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0955 - accuracy: 0.9866 - val_loss: 10.3713 - val_accuracy: 0.6809\n",
            "Epoch 242/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0779 - accuracy: 0.9879 - val_loss: 10.9181 - val_accuracy: 0.6829\n",
            "Epoch 243/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0999 - accuracy: 0.9867 - val_loss: 10.7104 - val_accuracy: 0.6839\n",
            "Epoch 244/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0661 - accuracy: 0.9901 - val_loss: 10.4605 - val_accuracy: 0.6910\n",
            "Epoch 245/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0909 - accuracy: 0.9868 - val_loss: 10.8274 - val_accuracy: 0.6823\n",
            "Epoch 246/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0776 - accuracy: 0.9883 - val_loss: 11.2801 - val_accuracy: 0.6800\n",
            "Epoch 247/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0791 - accuracy: 0.9892 - val_loss: 11.2285 - val_accuracy: 0.6890\n",
            "Epoch 248/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0967 - accuracy: 0.9866 - val_loss: 10.8558 - val_accuracy: 0.6777\n",
            "Epoch 249/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0862 - accuracy: 0.9878 - val_loss: 11.3946 - val_accuracy: 0.6801\n",
            "Epoch 250/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0883 - accuracy: 0.9880 - val_loss: 11.7074 - val_accuracy: 0.6862\n",
            "Epoch 251/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0911 - accuracy: 0.9884 - val_loss: 11.6833 - val_accuracy: 0.6876\n",
            "Epoch 252/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0935 - accuracy: 0.9881 - val_loss: 11.4525 - val_accuracy: 0.6733\n",
            "Epoch 253/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0959 - accuracy: 0.9872 - val_loss: 11.6410 - val_accuracy: 0.6744\n",
            "Epoch 254/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0784 - accuracy: 0.9885 - val_loss: 11.7654 - val_accuracy: 0.6788\n",
            "Epoch 255/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0855 - accuracy: 0.9886 - val_loss: 12.2054 - val_accuracy: 0.6797\n",
            "Epoch 256/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1112 - accuracy: 0.9869 - val_loss: 11.5031 - val_accuracy: 0.6831\n",
            "Epoch 257/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0785 - accuracy: 0.9895 - val_loss: 11.9287 - val_accuracy: 0.6779\n",
            "Epoch 258/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1143 - accuracy: 0.9863 - val_loss: 12.1661 - val_accuracy: 0.6793\n",
            "Epoch 259/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0952 - accuracy: 0.9878 - val_loss: 12.0508 - val_accuracy: 0.6751\n",
            "Epoch 260/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0882 - accuracy: 0.9892 - val_loss: 11.6564 - val_accuracy: 0.6735\n",
            "Epoch 261/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0962 - accuracy: 0.9883 - val_loss: 11.9456 - val_accuracy: 0.6773\n",
            "Epoch 262/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0871 - accuracy: 0.9885 - val_loss: 11.9041 - val_accuracy: 0.6832\n",
            "Epoch 263/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0876 - accuracy: 0.9892 - val_loss: 12.0451 - val_accuracy: 0.6793\n",
            "Epoch 264/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0932 - accuracy: 0.9889 - val_loss: 12.1058 - val_accuracy: 0.6803\n",
            "Epoch 265/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0904 - accuracy: 0.9885 - val_loss: 12.2101 - val_accuracy: 0.6816\n",
            "Epoch 266/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0894 - accuracy: 0.9888 - val_loss: 12.9867 - val_accuracy: 0.6784\n",
            "Epoch 267/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1032 - accuracy: 0.9878 - val_loss: 12.6322 - val_accuracy: 0.6858\n",
            "Epoch 268/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0874 - accuracy: 0.9890 - val_loss: 12.6783 - val_accuracy: 0.6861\n",
            "Epoch 269/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1012 - accuracy: 0.9881 - val_loss: 12.6975 - val_accuracy: 0.6857\n",
            "Epoch 270/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0830 - accuracy: 0.9897 - val_loss: 12.2947 - val_accuracy: 0.6817\n",
            "Epoch 271/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0934 - accuracy: 0.9882 - val_loss: 12.9148 - val_accuracy: 0.6780\n",
            "Epoch 272/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0949 - accuracy: 0.9882 - val_loss: 12.7868 - val_accuracy: 0.6760\n",
            "Epoch 273/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0977 - accuracy: 0.9885 - val_loss: 13.1521 - val_accuracy: 0.6769\n",
            "Epoch 274/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0816 - accuracy: 0.9896 - val_loss: 13.8008 - val_accuracy: 0.6757\n",
            "Epoch 275/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0956 - accuracy: 0.9887 - val_loss: 12.8837 - val_accuracy: 0.6790\n",
            "Epoch 276/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1002 - accuracy: 0.9882 - val_loss: 12.9128 - val_accuracy: 0.6820\n",
            "Epoch 277/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0902 - accuracy: 0.9885 - val_loss: 13.2089 - val_accuracy: 0.6843\n",
            "Epoch 278/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0991 - accuracy: 0.9881 - val_loss: 13.0813 - val_accuracy: 0.6799\n",
            "Epoch 279/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0917 - accuracy: 0.9888 - val_loss: 13.5370 - val_accuracy: 0.6814\n",
            "Epoch 280/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1114 - accuracy: 0.9879 - val_loss: 13.2641 - val_accuracy: 0.6842\n",
            "Epoch 281/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0920 - accuracy: 0.9895 - val_loss: 13.8872 - val_accuracy: 0.6796\n",
            "Epoch 282/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0920 - accuracy: 0.9894 - val_loss: 13.7668 - val_accuracy: 0.6806\n",
            "Epoch 283/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0874 - accuracy: 0.9891 - val_loss: 13.1084 - val_accuracy: 0.6848\n",
            "Epoch 284/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0936 - accuracy: 0.9892 - val_loss: 13.7337 - val_accuracy: 0.6874\n",
            "Epoch 285/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1100 - accuracy: 0.9871 - val_loss: 13.3838 - val_accuracy: 0.6856\n",
            "Epoch 286/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0915 - accuracy: 0.9894 - val_loss: 14.1761 - val_accuracy: 0.6822\n",
            "Epoch 287/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0915 - accuracy: 0.9889 - val_loss: 14.1711 - val_accuracy: 0.6825\n",
            "Epoch 288/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0950 - accuracy: 0.9891 - val_loss: 13.7265 - val_accuracy: 0.6797\n",
            "Epoch 289/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1049 - accuracy: 0.9881 - val_loss: 14.2528 - val_accuracy: 0.6796\n",
            "Epoch 290/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0931 - accuracy: 0.9898 - val_loss: 13.6784 - val_accuracy: 0.6852\n",
            "Epoch 291/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1003 - accuracy: 0.9891 - val_loss: 14.0366 - val_accuracy: 0.6807\n",
            "Epoch 292/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0910 - accuracy: 0.9893 - val_loss: 14.4551 - val_accuracy: 0.6757\n",
            "Epoch 293/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1001 - accuracy: 0.9886 - val_loss: 14.8354 - val_accuracy: 0.6867\n",
            "Epoch 294/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1016 - accuracy: 0.9889 - val_loss: 14.1467 - val_accuracy: 0.6771\n",
            "Epoch 295/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1074 - accuracy: 0.9885 - val_loss: 14.6181 - val_accuracy: 0.6884\n",
            "Epoch 296/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0970 - accuracy: 0.9895 - val_loss: 14.9999 - val_accuracy: 0.6834\n",
            "Epoch 297/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1073 - accuracy: 0.9895 - val_loss: 15.1584 - val_accuracy: 0.6737\n",
            "Epoch 298/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1093 - accuracy: 0.9884 - val_loss: 15.5335 - val_accuracy: 0.6781\n",
            "Epoch 299/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1075 - accuracy: 0.9897 - val_loss: 15.1686 - val_accuracy: 0.6742\n",
            "Epoch 300/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1003 - accuracy: 0.9899 - val_loss: 15.2278 - val_accuracy: 0.6818\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 15.2278 - accuracy: 0.6818\n",
            "Training Time: 2844.90 seconds\n",
            "Training Loss: 0.1003\n",
            "Test Accuracy: 0.6818\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))  # Adjust the number of output classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test))\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1B\n"
      ],
      "metadata": {
        "id": "O3uTGzSD877e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the extended CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # Additional Convolutional Layer\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))  # Adjusted fully connected layer\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test))\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJQCgRbg8-X8",
        "outputId": "e0c68805-b0bf-4fd5-932d-4ca36d1853d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 22s 7ms/step - loss: 1.4738 - accuracy: 0.4637 - val_loss: 1.1972 - val_accuracy: 0.5707\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0830 - accuracy: 0.6179 - val_loss: 1.0121 - val_accuracy: 0.6441\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9254 - accuracy: 0.6778 - val_loss: 0.9587 - val_accuracy: 0.6693\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8149 - accuracy: 0.7134 - val_loss: 0.9196 - val_accuracy: 0.6849\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7281 - accuracy: 0.7439 - val_loss: 0.8911 - val_accuracy: 0.6980\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6601 - accuracy: 0.7688 - val_loss: 0.8192 - val_accuracy: 0.7255\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5920 - accuracy: 0.7922 - val_loss: 0.8510 - val_accuracy: 0.7155\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5424 - accuracy: 0.8074 - val_loss: 0.8733 - val_accuracy: 0.7120\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4867 - accuracy: 0.8283 - val_loss: 0.8554 - val_accuracy: 0.7258\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4400 - accuracy: 0.8434 - val_loss: 0.9102 - val_accuracy: 0.7180\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4003 - accuracy: 0.8567 - val_loss: 0.9425 - val_accuracy: 0.7221\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3572 - accuracy: 0.8726 - val_loss: 1.0383 - val_accuracy: 0.7117\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3199 - accuracy: 0.8851 - val_loss: 1.0417 - val_accuracy: 0.7202\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2800 - accuracy: 0.9005 - val_loss: 1.0974 - val_accuracy: 0.7258\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2609 - accuracy: 0.9064 - val_loss: 1.1582 - val_accuracy: 0.7195\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2360 - accuracy: 0.9140 - val_loss: 1.2094 - val_accuracy: 0.7185\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2177 - accuracy: 0.9215 - val_loss: 1.2837 - val_accuracy: 0.7049\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1997 - accuracy: 0.9273 - val_loss: 1.3842 - val_accuracy: 0.7077\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1871 - accuracy: 0.9329 - val_loss: 1.4313 - val_accuracy: 0.7056\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 1.5483 - val_accuracy: 0.7052\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1674 - accuracy: 0.9398 - val_loss: 1.5559 - val_accuracy: 0.7076\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1554 - accuracy: 0.9445 - val_loss: 1.5958 - val_accuracy: 0.7080\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1440 - accuracy: 0.9486 - val_loss: 1.6852 - val_accuracy: 0.7192\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1453 - accuracy: 0.9490 - val_loss: 1.7604 - val_accuracy: 0.7053\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1440 - accuracy: 0.9506 - val_loss: 1.7306 - val_accuracy: 0.7021\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1295 - accuracy: 0.9556 - val_loss: 1.8848 - val_accuracy: 0.7029\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1272 - accuracy: 0.9558 - val_loss: 1.9943 - val_accuracy: 0.6941\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1299 - accuracy: 0.9548 - val_loss: 1.9413 - val_accuracy: 0.7086\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1252 - accuracy: 0.9564 - val_loss: 2.0285 - val_accuracy: 0.7101\n",
            "Epoch 30/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1248 - accuracy: 0.9568 - val_loss: 2.1082 - val_accuracy: 0.7044\n",
            "Epoch 31/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1129 - accuracy: 0.9613 - val_loss: 2.1520 - val_accuracy: 0.6902\n",
            "Epoch 32/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1230 - accuracy: 0.9582 - val_loss: 2.1301 - val_accuracy: 0.6980\n",
            "Epoch 33/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1079 - accuracy: 0.9627 - val_loss: 2.0738 - val_accuracy: 0.7074\n",
            "Epoch 34/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1099 - accuracy: 0.9627 - val_loss: 2.1567 - val_accuracy: 0.7009\n",
            "Epoch 35/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1116 - accuracy: 0.9629 - val_loss: 2.2847 - val_accuracy: 0.7028\n",
            "Epoch 36/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1082 - accuracy: 0.9646 - val_loss: 2.2148 - val_accuracy: 0.7049\n",
            "Epoch 37/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1064 - accuracy: 0.9658 - val_loss: 2.2743 - val_accuracy: 0.7073\n",
            "Epoch 38/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1074 - accuracy: 0.9644 - val_loss: 2.2547 - val_accuracy: 0.7035\n",
            "Epoch 39/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1029 - accuracy: 0.9656 - val_loss: 2.3593 - val_accuracy: 0.7045\n",
            "Epoch 40/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1011 - accuracy: 0.9659 - val_loss: 2.4404 - val_accuracy: 0.7025\n",
            "Epoch 41/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1007 - accuracy: 0.9675 - val_loss: 2.4267 - val_accuracy: 0.7053\n",
            "Epoch 42/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1064 - accuracy: 0.9663 - val_loss: 2.4808 - val_accuracy: 0.7082\n",
            "Epoch 43/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0911 - accuracy: 0.9693 - val_loss: 2.5510 - val_accuracy: 0.7098\n",
            "Epoch 44/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1072 - accuracy: 0.9663 - val_loss: 2.5070 - val_accuracy: 0.7095\n",
            "Epoch 45/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1001 - accuracy: 0.9675 - val_loss: 2.5818 - val_accuracy: 0.7090\n",
            "Epoch 46/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0998 - accuracy: 0.9688 - val_loss: 2.5792 - val_accuracy: 0.7047\n",
            "Epoch 47/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0928 - accuracy: 0.9704 - val_loss: 2.6689 - val_accuracy: 0.7070\n",
            "Epoch 48/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0954 - accuracy: 0.9698 - val_loss: 2.6147 - val_accuracy: 0.7108\n",
            "Epoch 49/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1006 - accuracy: 0.9702 - val_loss: 2.7961 - val_accuracy: 0.7030\n",
            "Epoch 50/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0929 - accuracy: 0.9704 - val_loss: 2.7284 - val_accuracy: 0.7058\n",
            "Epoch 51/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0939 - accuracy: 0.9704 - val_loss: 2.7209 - val_accuracy: 0.7115\n",
            "Epoch 52/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0915 - accuracy: 0.9717 - val_loss: 2.8732 - val_accuracy: 0.6981\n",
            "Epoch 53/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0903 - accuracy: 0.9710 - val_loss: 2.8090 - val_accuracy: 0.7038\n",
            "Epoch 54/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0943 - accuracy: 0.9719 - val_loss: 2.8761 - val_accuracy: 0.6939\n",
            "Epoch 55/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1004 - accuracy: 0.9690 - val_loss: 2.7827 - val_accuracy: 0.7018\n",
            "Epoch 56/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0837 - accuracy: 0.9741 - val_loss: 2.8647 - val_accuracy: 0.7098\n",
            "Epoch 57/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0954 - accuracy: 0.9717 - val_loss: 2.8975 - val_accuracy: 0.7021\n",
            "Epoch 58/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0863 - accuracy: 0.9734 - val_loss: 3.0428 - val_accuracy: 0.6869\n",
            "Epoch 59/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0841 - accuracy: 0.9739 - val_loss: 2.9347 - val_accuracy: 0.7033\n",
            "Epoch 60/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0906 - accuracy: 0.9731 - val_loss: 2.9242 - val_accuracy: 0.7016\n",
            "Epoch 61/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0889 - accuracy: 0.9735 - val_loss: 3.0516 - val_accuracy: 0.6955\n",
            "Epoch 62/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0915 - accuracy: 0.9719 - val_loss: 3.0373 - val_accuracy: 0.7060\n",
            "Epoch 63/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0856 - accuracy: 0.9738 - val_loss: 3.0172 - val_accuracy: 0.6988\n",
            "Epoch 64/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0858 - accuracy: 0.9748 - val_loss: 3.2155 - val_accuracy: 0.7023\n",
            "Epoch 65/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0880 - accuracy: 0.9748 - val_loss: 3.2063 - val_accuracy: 0.7016\n",
            "Epoch 66/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0841 - accuracy: 0.9758 - val_loss: 2.9996 - val_accuracy: 0.7102\n",
            "Epoch 67/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0975 - accuracy: 0.9720 - val_loss: 3.2089 - val_accuracy: 0.7027\n",
            "Epoch 68/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0748 - accuracy: 0.9772 - val_loss: 3.3310 - val_accuracy: 0.7039\n",
            "Epoch 69/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0899 - accuracy: 0.9737 - val_loss: 3.2031 - val_accuracy: 0.7082\n",
            "Epoch 70/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0819 - accuracy: 0.9766 - val_loss: 3.2105 - val_accuracy: 0.7105\n",
            "Epoch 71/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0792 - accuracy: 0.9767 - val_loss: 3.3602 - val_accuracy: 0.7001\n",
            "Epoch 72/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0889 - accuracy: 0.9740 - val_loss: 3.4695 - val_accuracy: 0.6964\n",
            "Epoch 73/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0852 - accuracy: 0.9756 - val_loss: 3.2466 - val_accuracy: 0.7097\n",
            "Epoch 74/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0758 - accuracy: 0.9781 - val_loss: 3.3919 - val_accuracy: 0.7066\n",
            "Epoch 75/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0952 - accuracy: 0.9745 - val_loss: 3.2921 - val_accuracy: 0.7085\n",
            "Epoch 76/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0876 - accuracy: 0.9761 - val_loss: 3.3804 - val_accuracy: 0.7053\n",
            "Epoch 77/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0781 - accuracy: 0.9782 - val_loss: 3.4138 - val_accuracy: 0.7101\n",
            "Epoch 78/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0847 - accuracy: 0.9763 - val_loss: 3.6173 - val_accuracy: 0.6929\n",
            "Epoch 79/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0858 - accuracy: 0.9756 - val_loss: 3.7419 - val_accuracy: 0.7049\n",
            "Epoch 80/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0866 - accuracy: 0.9763 - val_loss: 3.4442 - val_accuracy: 0.7071\n",
            "Epoch 81/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0797 - accuracy: 0.9776 - val_loss: 3.5696 - val_accuracy: 0.7064\n",
            "Epoch 82/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0813 - accuracy: 0.9773 - val_loss: 3.5109 - val_accuracy: 0.7091\n",
            "Epoch 83/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0886 - accuracy: 0.9759 - val_loss: 3.6340 - val_accuracy: 0.7024\n",
            "Epoch 84/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0792 - accuracy: 0.9788 - val_loss: 3.6848 - val_accuracy: 0.7020\n",
            "Epoch 85/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0820 - accuracy: 0.9775 - val_loss: 3.5953 - val_accuracy: 0.7022\n",
            "Epoch 86/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0799 - accuracy: 0.9793 - val_loss: 3.6393 - val_accuracy: 0.6964\n",
            "Epoch 87/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0826 - accuracy: 0.9770 - val_loss: 3.5161 - val_accuracy: 0.7066\n",
            "Epoch 88/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0815 - accuracy: 0.9783 - val_loss: 3.7897 - val_accuracy: 0.6982\n",
            "Epoch 89/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0823 - accuracy: 0.9781 - val_loss: 3.6887 - val_accuracy: 0.6989\n",
            "Epoch 90/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0882 - accuracy: 0.9770 - val_loss: 3.7356 - val_accuracy: 0.6967\n",
            "Epoch 91/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0784 - accuracy: 0.9796 - val_loss: 3.7034 - val_accuracy: 0.7062\n",
            "Epoch 92/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0815 - accuracy: 0.9783 - val_loss: 3.7905 - val_accuracy: 0.7035\n",
            "Epoch 93/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0860 - accuracy: 0.9776 - val_loss: 3.8937 - val_accuracy: 0.7088\n",
            "Epoch 94/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0848 - accuracy: 0.9783 - val_loss: 3.6599 - val_accuracy: 0.7004\n",
            "Epoch 95/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0879 - accuracy: 0.9772 - val_loss: 3.8265 - val_accuracy: 0.7076\n",
            "Epoch 96/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0699 - accuracy: 0.9811 - val_loss: 3.8756 - val_accuracy: 0.7059\n",
            "Epoch 97/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0886 - accuracy: 0.9775 - val_loss: 4.0673 - val_accuracy: 0.7084\n",
            "Epoch 98/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0814 - accuracy: 0.9790 - val_loss: 3.9837 - val_accuracy: 0.6948\n",
            "Epoch 99/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0752 - accuracy: 0.9800 - val_loss: 4.2014 - val_accuracy: 0.6927\n",
            "Epoch 100/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0780 - accuracy: 0.9797 - val_loss: 4.1172 - val_accuracy: 0.6943\n",
            "Epoch 101/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0769 - accuracy: 0.9800 - val_loss: 4.0350 - val_accuracy: 0.6988\n",
            "Epoch 102/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0802 - accuracy: 0.9792 - val_loss: 4.1442 - val_accuracy: 0.7043\n",
            "Epoch 103/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0942 - accuracy: 0.9759 - val_loss: 3.9069 - val_accuracy: 0.7044\n",
            "Epoch 104/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0847 - accuracy: 0.9782 - val_loss: 4.0072 - val_accuracy: 0.7004\n",
            "Epoch 105/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0757 - accuracy: 0.9803 - val_loss: 4.1326 - val_accuracy: 0.7021\n",
            "Epoch 106/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0757 - accuracy: 0.9806 - val_loss: 4.1286 - val_accuracy: 0.7080\n",
            "Epoch 107/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0762 - accuracy: 0.9810 - val_loss: 4.3064 - val_accuracy: 0.7077\n",
            "Epoch 108/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0891 - accuracy: 0.9782 - val_loss: 4.2338 - val_accuracy: 0.7117\n",
            "Epoch 109/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0717 - accuracy: 0.9813 - val_loss: 4.2207 - val_accuracy: 0.7008\n",
            "Epoch 110/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0777 - accuracy: 0.9804 - val_loss: 4.2683 - val_accuracy: 0.7103\n",
            "Epoch 111/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0726 - accuracy: 0.9818 - val_loss: 4.1440 - val_accuracy: 0.7071\n",
            "Epoch 112/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0855 - accuracy: 0.9785 - val_loss: 4.3732 - val_accuracy: 0.7030\n",
            "Epoch 113/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0782 - accuracy: 0.9803 - val_loss: 4.3459 - val_accuracy: 0.7093\n",
            "Epoch 114/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0794 - accuracy: 0.9806 - val_loss: 4.4530 - val_accuracy: 0.7018\n",
            "Epoch 115/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0782 - accuracy: 0.9801 - val_loss: 4.4602 - val_accuracy: 0.6890\n",
            "Epoch 116/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0783 - accuracy: 0.9804 - val_loss: 4.5393 - val_accuracy: 0.7041\n",
            "Epoch 117/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0852 - accuracy: 0.9793 - val_loss: 4.3806 - val_accuracy: 0.6970\n",
            "Epoch 118/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0783 - accuracy: 0.9811 - val_loss: 4.4372 - val_accuracy: 0.7035\n",
            "Epoch 119/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0759 - accuracy: 0.9814 - val_loss: 4.5562 - val_accuracy: 0.7007\n",
            "Epoch 120/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0749 - accuracy: 0.9814 - val_loss: 4.6301 - val_accuracy: 0.7067\n",
            "Epoch 121/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0758 - accuracy: 0.9817 - val_loss: 4.5758 - val_accuracy: 0.7060\n",
            "Epoch 122/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0801 - accuracy: 0.9805 - val_loss: 4.7286 - val_accuracy: 0.7044\n",
            "Epoch 123/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0737 - accuracy: 0.9823 - val_loss: 4.5830 - val_accuracy: 0.7033\n",
            "Epoch 124/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0850 - accuracy: 0.9806 - val_loss: 4.4900 - val_accuracy: 0.6930\n",
            "Epoch 125/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0698 - accuracy: 0.9823 - val_loss: 4.5279 - val_accuracy: 0.6985\n",
            "Epoch 126/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0749 - accuracy: 0.9822 - val_loss: 4.4930 - val_accuracy: 0.7019\n",
            "Epoch 127/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0764 - accuracy: 0.9820 - val_loss: 4.5479 - val_accuracy: 0.7066\n",
            "Epoch 128/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0805 - accuracy: 0.9804 - val_loss: 4.7172 - val_accuracy: 0.7021\n",
            "Epoch 129/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0795 - accuracy: 0.9812 - val_loss: 4.8699 - val_accuracy: 0.6988\n",
            "Epoch 130/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0733 - accuracy: 0.9823 - val_loss: 4.9318 - val_accuracy: 0.6989\n",
            "Epoch 131/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0830 - accuracy: 0.9804 - val_loss: 4.8509 - val_accuracy: 0.6993\n",
            "Epoch 132/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0834 - accuracy: 0.9809 - val_loss: 4.9819 - val_accuracy: 0.7074\n",
            "Epoch 133/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0783 - accuracy: 0.9819 - val_loss: 5.0444 - val_accuracy: 0.6957\n",
            "Epoch 134/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0715 - accuracy: 0.9831 - val_loss: 5.2234 - val_accuracy: 0.7021\n",
            "Epoch 135/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0910 - accuracy: 0.9801 - val_loss: 5.0067 - val_accuracy: 0.6955\n",
            "Epoch 136/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0704 - accuracy: 0.9836 - val_loss: 5.0551 - val_accuracy: 0.6905\n",
            "Epoch 137/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0815 - accuracy: 0.9818 - val_loss: 5.1955 - val_accuracy: 0.6968\n",
            "Epoch 138/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0840 - accuracy: 0.9819 - val_loss: 4.9200 - val_accuracy: 0.7040\n",
            "Epoch 139/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0760 - accuracy: 0.9826 - val_loss: 5.1154 - val_accuracy: 0.6983\n",
            "Epoch 140/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0867 - accuracy: 0.9814 - val_loss: 4.9323 - val_accuracy: 0.6983\n",
            "Epoch 141/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0796 - accuracy: 0.9829 - val_loss: 5.0963 - val_accuracy: 0.7031\n",
            "Epoch 142/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0840 - accuracy: 0.9819 - val_loss: 5.1349 - val_accuracy: 0.6909\n",
            "Epoch 143/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0686 - accuracy: 0.9838 - val_loss: 5.3371 - val_accuracy: 0.6974\n",
            "Epoch 144/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0868 - accuracy: 0.9819 - val_loss: 5.2803 - val_accuracy: 0.6995\n",
            "Epoch 145/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0762 - accuracy: 0.9828 - val_loss: 5.1756 - val_accuracy: 0.7067\n",
            "Epoch 146/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0800 - accuracy: 0.9823 - val_loss: 5.5195 - val_accuracy: 0.6909\n",
            "Epoch 147/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9824 - val_loss: 5.3687 - val_accuracy: 0.6978\n",
            "Epoch 148/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0809 - accuracy: 0.9818 - val_loss: 5.6331 - val_accuracy: 0.7031\n",
            "Epoch 149/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0869 - accuracy: 0.9822 - val_loss: 5.4490 - val_accuracy: 0.6997\n",
            "Epoch 150/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0856 - accuracy: 0.9816 - val_loss: 5.6084 - val_accuracy: 0.7071\n",
            "Epoch 151/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0787 - accuracy: 0.9836 - val_loss: 5.5457 - val_accuracy: 0.6988\n",
            "Epoch 152/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0774 - accuracy: 0.9837 - val_loss: 5.4261 - val_accuracy: 0.7076\n",
            "Epoch 153/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0881 - accuracy: 0.9822 - val_loss: 5.5312 - val_accuracy: 0.7021\n",
            "Epoch 154/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0812 - accuracy: 0.9837 - val_loss: 5.4759 - val_accuracy: 0.7004\n",
            "Epoch 155/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0859 - accuracy: 0.9822 - val_loss: 5.5440 - val_accuracy: 0.7035\n",
            "Epoch 156/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0754 - accuracy: 0.9842 - val_loss: 5.5932 - val_accuracy: 0.6983\n",
            "Epoch 157/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0721 - accuracy: 0.9846 - val_loss: 5.5977 - val_accuracy: 0.7030\n",
            "Epoch 158/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0793 - accuracy: 0.9834 - val_loss: 5.7622 - val_accuracy: 0.6952\n",
            "Epoch 159/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0858 - accuracy: 0.9822 - val_loss: 5.8740 - val_accuracy: 0.6916\n",
            "Epoch 160/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0798 - accuracy: 0.9832 - val_loss: 5.7658 - val_accuracy: 0.7081\n",
            "Epoch 161/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0735 - accuracy: 0.9851 - val_loss: 5.5906 - val_accuracy: 0.6949\n",
            "Epoch 162/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0816 - accuracy: 0.9827 - val_loss: 5.8760 - val_accuracy: 0.7003\n",
            "Epoch 163/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0859 - accuracy: 0.9822 - val_loss: 5.8809 - val_accuracy: 0.7036\n",
            "Epoch 164/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0803 - accuracy: 0.9836 - val_loss: 5.9245 - val_accuracy: 0.6954\n",
            "Epoch 165/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0883 - accuracy: 0.9829 - val_loss: 5.8666 - val_accuracy: 0.6936\n",
            "Epoch 166/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0829 - accuracy: 0.9833 - val_loss: 6.1358 - val_accuracy: 0.6951\n",
            "Epoch 167/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0722 - accuracy: 0.9850 - val_loss: 6.2433 - val_accuracy: 0.7013\n",
            "Epoch 168/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0826 - accuracy: 0.9838 - val_loss: 6.0544 - val_accuracy: 0.7067\n",
            "Epoch 169/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0864 - accuracy: 0.9832 - val_loss: 6.1815 - val_accuracy: 0.7029\n",
            "Epoch 170/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0810 - accuracy: 0.9844 - val_loss: 6.1502 - val_accuracy: 0.6944\n",
            "Epoch 171/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0856 - accuracy: 0.9833 - val_loss: 6.4723 - val_accuracy: 0.6989\n",
            "Epoch 172/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0962 - accuracy: 0.9824 - val_loss: 6.1305 - val_accuracy: 0.6962\n",
            "Epoch 173/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0733 - accuracy: 0.9859 - val_loss: 6.3153 - val_accuracy: 0.6991\n",
            "Epoch 174/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0935 - accuracy: 0.9832 - val_loss: 6.4401 - val_accuracy: 0.6967\n",
            "Epoch 175/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0766 - accuracy: 0.9851 - val_loss: 6.0317 - val_accuracy: 0.7046\n",
            "Epoch 176/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0881 - accuracy: 0.9838 - val_loss: 6.1617 - val_accuracy: 0.6992\n",
            "Epoch 177/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0820 - accuracy: 0.9837 - val_loss: 6.4548 - val_accuracy: 0.6972\n",
            "Epoch 178/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0867 - accuracy: 0.9829 - val_loss: 6.3482 - val_accuracy: 0.6935\n",
            "Epoch 179/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0765 - accuracy: 0.9845 - val_loss: 6.8005 - val_accuracy: 0.6973\n",
            "Epoch 180/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0864 - accuracy: 0.9839 - val_loss: 6.9172 - val_accuracy: 0.6931\n",
            "Epoch 181/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0796 - accuracy: 0.9849 - val_loss: 6.8212 - val_accuracy: 0.6986\n",
            "Epoch 182/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0922 - accuracy: 0.9829 - val_loss: 6.3944 - val_accuracy: 0.7009\n",
            "Epoch 183/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0905 - accuracy: 0.9845 - val_loss: 6.7045 - val_accuracy: 0.6961\n",
            "Epoch 184/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0745 - accuracy: 0.9859 - val_loss: 6.7074 - val_accuracy: 0.6989\n",
            "Epoch 185/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0785 - accuracy: 0.9841 - val_loss: 6.6017 - val_accuracy: 0.7040\n",
            "Epoch 186/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0900 - accuracy: 0.9832 - val_loss: 6.6770 - val_accuracy: 0.7009\n",
            "Epoch 187/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0765 - accuracy: 0.9849 - val_loss: 6.8973 - val_accuracy: 0.6984\n",
            "Epoch 188/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0825 - accuracy: 0.9845 - val_loss: 6.8540 - val_accuracy: 0.6988\n",
            "Epoch 189/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0889 - accuracy: 0.9841 - val_loss: 7.0665 - val_accuracy: 0.6972\n",
            "Epoch 190/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0895 - accuracy: 0.9838 - val_loss: 7.3655 - val_accuracy: 0.6991\n",
            "Epoch 191/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0880 - accuracy: 0.9845 - val_loss: 7.0720 - val_accuracy: 0.6997\n",
            "Epoch 192/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0887 - accuracy: 0.9843 - val_loss: 7.0362 - val_accuracy: 0.6957\n",
            "Epoch 193/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0795 - accuracy: 0.9851 - val_loss: 7.0214 - val_accuracy: 0.7005\n",
            "Epoch 194/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0944 - accuracy: 0.9845 - val_loss: 6.8862 - val_accuracy: 0.7041\n",
            "Epoch 195/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0888 - accuracy: 0.9851 - val_loss: 7.2554 - val_accuracy: 0.7023\n",
            "Epoch 196/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0779 - accuracy: 0.9867 - val_loss: 7.0751 - val_accuracy: 0.7027\n",
            "Epoch 197/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0927 - accuracy: 0.9837 - val_loss: 7.2590 - val_accuracy: 0.6968\n",
            "Epoch 198/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0897 - accuracy: 0.9847 - val_loss: 7.4331 - val_accuracy: 0.6941\n",
            "Epoch 199/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0968 - accuracy: 0.9841 - val_loss: 7.2865 - val_accuracy: 0.6993\n",
            "Epoch 200/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0773 - accuracy: 0.9861 - val_loss: 7.5375 - val_accuracy: 0.7066\n",
            "Epoch 201/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0866 - accuracy: 0.9852 - val_loss: 7.1409 - val_accuracy: 0.7104\n",
            "Epoch 202/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0975 - accuracy: 0.9839 - val_loss: 7.1159 - val_accuracy: 0.7014\n",
            "Epoch 203/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0917 - accuracy: 0.9843 - val_loss: 7.1466 - val_accuracy: 0.7049\n",
            "Epoch 204/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0780 - accuracy: 0.9860 - val_loss: 7.3871 - val_accuracy: 0.7079\n",
            "Epoch 205/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0818 - accuracy: 0.9850 - val_loss: 7.9182 - val_accuracy: 0.7009\n",
            "Epoch 206/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1004 - accuracy: 0.9847 - val_loss: 7.6306 - val_accuracy: 0.6985\n",
            "Epoch 207/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0903 - accuracy: 0.9854 - val_loss: 7.4993 - val_accuracy: 0.6967\n",
            "Epoch 208/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0848 - accuracy: 0.9859 - val_loss: 8.0003 - val_accuracy: 0.7040\n",
            "Epoch 209/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0827 - accuracy: 0.9864 - val_loss: 7.8781 - val_accuracy: 0.6960\n",
            "Epoch 210/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0922 - accuracy: 0.9847 - val_loss: 8.3134 - val_accuracy: 0.6937\n",
            "Epoch 211/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0826 - accuracy: 0.9865 - val_loss: 8.0523 - val_accuracy: 0.7021\n",
            "Epoch 212/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0903 - accuracy: 0.9848 - val_loss: 7.9229 - val_accuracy: 0.7089\n",
            "Epoch 213/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0912 - accuracy: 0.9859 - val_loss: 8.0166 - val_accuracy: 0.6912\n",
            "Epoch 214/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0986 - accuracy: 0.9847 - val_loss: 8.1469 - val_accuracy: 0.6974\n",
            "Epoch 215/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0844 - accuracy: 0.9859 - val_loss: 8.1774 - val_accuracy: 0.7006\n",
            "Epoch 216/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1008 - accuracy: 0.9854 - val_loss: 8.1693 - val_accuracy: 0.6952\n",
            "Epoch 217/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0948 - accuracy: 0.9847 - val_loss: 8.1619 - val_accuracy: 0.6974\n",
            "Epoch 218/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0919 - accuracy: 0.9858 - val_loss: 7.9228 - val_accuracy: 0.7038\n",
            "Epoch 219/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0932 - accuracy: 0.9861 - val_loss: 7.9094 - val_accuracy: 0.7038\n",
            "Epoch 220/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0873 - accuracy: 0.9859 - val_loss: 8.0666 - val_accuracy: 0.6987\n",
            "Epoch 221/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0954 - accuracy: 0.9855 - val_loss: 8.2238 - val_accuracy: 0.6920\n",
            "Epoch 222/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0834 - accuracy: 0.9866 - val_loss: 8.4174 - val_accuracy: 0.6927\n",
            "Epoch 223/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0849 - accuracy: 0.9869 - val_loss: 8.6549 - val_accuracy: 0.6977\n",
            "Epoch 224/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0958 - accuracy: 0.9852 - val_loss: 8.5330 - val_accuracy: 0.7031\n",
            "Epoch 225/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0934 - accuracy: 0.9855 - val_loss: 8.2023 - val_accuracy: 0.6993\n",
            "Epoch 226/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0821 - accuracy: 0.9879 - val_loss: 8.7231 - val_accuracy: 0.6969\n",
            "Epoch 227/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1025 - accuracy: 0.9858 - val_loss: 8.5265 - val_accuracy: 0.7013\n",
            "Epoch 228/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0923 - accuracy: 0.9863 - val_loss: 8.7391 - val_accuracy: 0.6926\n",
            "Epoch 229/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0869 - accuracy: 0.9867 - val_loss: 9.0607 - val_accuracy: 0.7071\n",
            "Epoch 230/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1001 - accuracy: 0.9857 - val_loss: 8.8952 - val_accuracy: 0.7017\n",
            "Epoch 231/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0906 - accuracy: 0.9862 - val_loss: 8.6706 - val_accuracy: 0.6983\n",
            "Epoch 232/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0799 - accuracy: 0.9875 - val_loss: 8.7765 - val_accuracy: 0.7007\n",
            "Epoch 233/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0978 - accuracy: 0.9854 - val_loss: 9.2299 - val_accuracy: 0.6913\n",
            "Epoch 234/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0860 - accuracy: 0.9870 - val_loss: 9.1314 - val_accuracy: 0.7005\n",
            "Epoch 235/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1245 - accuracy: 0.9835 - val_loss: 8.9671 - val_accuracy: 0.7037\n",
            "Epoch 236/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0827 - accuracy: 0.9883 - val_loss: 9.0477 - val_accuracy: 0.6982\n",
            "Epoch 237/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1008 - accuracy: 0.9859 - val_loss: 9.5853 - val_accuracy: 0.6837\n",
            "Epoch 238/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1015 - accuracy: 0.9862 - val_loss: 9.4588 - val_accuracy: 0.6981\n",
            "Epoch 239/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0977 - accuracy: 0.9859 - val_loss: 9.5567 - val_accuracy: 0.6999\n",
            "Epoch 240/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0952 - accuracy: 0.9872 - val_loss: 9.2350 - val_accuracy: 0.7019\n",
            "Epoch 241/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0982 - accuracy: 0.9863 - val_loss: 9.5191 - val_accuracy: 0.6976\n",
            "Epoch 242/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1066 - accuracy: 0.9857 - val_loss: 9.1573 - val_accuracy: 0.6996\n",
            "Epoch 243/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0752 - accuracy: 0.9890 - val_loss: 9.2182 - val_accuracy: 0.7014\n",
            "Epoch 244/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1086 - accuracy: 0.9859 - val_loss: 9.5991 - val_accuracy: 0.6959\n",
            "Epoch 245/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1023 - accuracy: 0.9860 - val_loss: 9.3346 - val_accuracy: 0.7034\n",
            "Epoch 246/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0878 - accuracy: 0.9876 - val_loss: 9.6046 - val_accuracy: 0.7015\n",
            "Epoch 247/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1086 - accuracy: 0.9854 - val_loss: 9.6861 - val_accuracy: 0.7032\n",
            "Epoch 248/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0949 - accuracy: 0.9871 - val_loss: 9.4599 - val_accuracy: 0.6990\n",
            "Epoch 249/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0891 - accuracy: 0.9876 - val_loss: 9.4795 - val_accuracy: 0.7044\n",
            "Epoch 250/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1049 - accuracy: 0.9860 - val_loss: 9.5752 - val_accuracy: 0.6996\n",
            "Epoch 251/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0932 - accuracy: 0.9868 - val_loss: 9.8801 - val_accuracy: 0.7041\n",
            "Epoch 252/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0982 - accuracy: 0.9872 - val_loss: 9.6935 - val_accuracy: 0.6998\n",
            "Epoch 253/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1068 - accuracy: 0.9856 - val_loss: 10.0448 - val_accuracy: 0.6949\n",
            "Epoch 254/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0928 - accuracy: 0.9873 - val_loss: 10.0336 - val_accuracy: 0.7043\n",
            "Epoch 255/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1083 - accuracy: 0.9854 - val_loss: 9.8897 - val_accuracy: 0.6979\n",
            "Epoch 256/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0992 - accuracy: 0.9871 - val_loss: 10.1910 - val_accuracy: 0.7026\n",
            "Epoch 257/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0983 - accuracy: 0.9866 - val_loss: 10.3690 - val_accuracy: 0.7008\n",
            "Epoch 258/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1046 - accuracy: 0.9867 - val_loss: 10.0371 - val_accuracy: 0.7046\n",
            "Epoch 259/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0992 - accuracy: 0.9866 - val_loss: 10.6384 - val_accuracy: 0.7054\n",
            "Epoch 260/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0952 - accuracy: 0.9878 - val_loss: 10.5172 - val_accuracy: 0.6995\n",
            "Epoch 261/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1008 - accuracy: 0.9874 - val_loss: 10.6805 - val_accuracy: 0.7027\n",
            "Epoch 262/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1049 - accuracy: 0.9863 - val_loss: 10.9421 - val_accuracy: 0.6924\n",
            "Epoch 263/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1039 - accuracy: 0.9874 - val_loss: 10.3799 - val_accuracy: 0.6954\n",
            "Epoch 264/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1051 - accuracy: 0.9866 - val_loss: 11.3512 - val_accuracy: 0.6947\n",
            "Epoch 265/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0980 - accuracy: 0.9880 - val_loss: 10.8225 - val_accuracy: 0.6953\n",
            "Epoch 266/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1196 - accuracy: 0.9850 - val_loss: 11.0985 - val_accuracy: 0.6921\n",
            "Epoch 267/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0976 - accuracy: 0.9877 - val_loss: 10.3870 - val_accuracy: 0.6950\n",
            "Epoch 268/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0974 - accuracy: 0.9873 - val_loss: 10.6457 - val_accuracy: 0.6953\n",
            "Epoch 269/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0902 - accuracy: 0.9881 - val_loss: 11.0047 - val_accuracy: 0.6925\n",
            "Epoch 270/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1093 - accuracy: 0.9868 - val_loss: 11.3111 - val_accuracy: 0.7007\n",
            "Epoch 271/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1193 - accuracy: 0.9862 - val_loss: 11.0504 - val_accuracy: 0.6995\n",
            "Epoch 272/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0980 - accuracy: 0.9876 - val_loss: 11.4763 - val_accuracy: 0.7062\n",
            "Epoch 273/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1020 - accuracy: 0.9881 - val_loss: 10.9943 - val_accuracy: 0.7005\n",
            "Epoch 274/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1038 - accuracy: 0.9875 - val_loss: 10.9225 - val_accuracy: 0.6998\n",
            "Epoch 275/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0951 - accuracy: 0.9877 - val_loss: 11.1987 - val_accuracy: 0.6963\n",
            "Epoch 276/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1123 - accuracy: 0.9868 - val_loss: 11.3361 - val_accuracy: 0.7034\n",
            "Epoch 277/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1102 - accuracy: 0.9875 - val_loss: 11.7401 - val_accuracy: 0.6955\n",
            "Epoch 278/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0920 - accuracy: 0.9882 - val_loss: 11.6608 - val_accuracy: 0.6942\n",
            "Epoch 279/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1156 - accuracy: 0.9871 - val_loss: 11.9573 - val_accuracy: 0.6939\n",
            "Epoch 280/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0978 - accuracy: 0.9882 - val_loss: 11.3553 - val_accuracy: 0.7047\n",
            "Epoch 281/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1102 - accuracy: 0.9878 - val_loss: 12.3504 - val_accuracy: 0.6852\n",
            "Epoch 282/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1092 - accuracy: 0.9876 - val_loss: 12.0578 - val_accuracy: 0.7000\n",
            "Epoch 283/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1097 - accuracy: 0.9873 - val_loss: 12.2263 - val_accuracy: 0.6964\n",
            "Epoch 284/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1240 - accuracy: 0.9866 - val_loss: 11.9051 - val_accuracy: 0.7000\n",
            "Epoch 285/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1065 - accuracy: 0.9885 - val_loss: 12.0963 - val_accuracy: 0.6959\n",
            "Epoch 286/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1108 - accuracy: 0.9873 - val_loss: 12.6423 - val_accuracy: 0.7006\n",
            "Epoch 287/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0966 - accuracy: 0.9889 - val_loss: 12.4093 - val_accuracy: 0.6984\n",
            "Epoch 288/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1251 - accuracy: 0.9860 - val_loss: 12.9192 - val_accuracy: 0.7055\n",
            "Epoch 289/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1064 - accuracy: 0.9880 - val_loss: 12.1093 - val_accuracy: 0.6999\n",
            "Epoch 290/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0931 - accuracy: 0.9896 - val_loss: 12.6251 - val_accuracy: 0.7039\n",
            "Epoch 291/300\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1150 - accuracy: 0.9874 - val_loss: 12.7070 - val_accuracy: 0.7008\n",
            "Epoch 292/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1088 - accuracy: 0.9877 - val_loss: 12.7446 - val_accuracy: 0.6970\n",
            "Epoch 293/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1185 - accuracy: 0.9869 - val_loss: 12.6170 - val_accuracy: 0.7055\n",
            "Epoch 294/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1056 - accuracy: 0.9886 - val_loss: 13.2878 - val_accuracy: 0.6888\n",
            "Epoch 295/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0932 - accuracy: 0.9899 - val_loss: 12.3347 - val_accuracy: 0.6992\n",
            "Epoch 296/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1255 - accuracy: 0.9870 - val_loss: 13.0167 - val_accuracy: 0.6991\n",
            "Epoch 297/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1110 - accuracy: 0.9875 - val_loss: 12.7451 - val_accuracy: 0.6957\n",
            "Epoch 298/300\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1154 - accuracy: 0.9879 - val_loss: 13.2823 - val_accuracy: 0.7016\n",
            "Epoch 299/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1079 - accuracy: 0.9886 - val_loss: 13.2475 - val_accuracy: 0.6987\n",
            "Epoch 300/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1051 - accuracy: 0.9886 - val_loss: 13.1927 - val_accuracy: 0.6928\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 13.1927 - accuracy: 0.6928\n",
            "Training Time: 2865.74 seconds\n",
            "Training Loss: 0.1051\n",
            "Test Accuracy: 0.6928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2A"
      ],
      "metadata": {
        "id": "Z7OAI2n7J6CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Define the residual block\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    shortcut = x\n",
        "\n",
        "    # First convolution layer\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Second convolution layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Skip connection\n",
        "    if stride != 1 or shortcut.shape[-1] != filters:\n",
        "        shortcut = layers.Conv2D(filters, 1, strides=stride)(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# Build a smaller ResNet-10 model\n",
        "def build_resnet10():\n",
        "    input_shape = (32, 32, 3)\n",
        "    num_classes = 10\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution layer\n",
        "    x = layers.Conv2D(16, 3, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(10):\n",
        "        x = residual_block(x, 16)\n",
        "\n",
        "    # Global average pooling\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully connected layer\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build and compile the smaller ResNet-10 model\n",
        "resnet10_model = build_resnet10()\n",
        "resnet10_model.compile(optimizer='adam',\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Configure early stopping\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model for 300 epochs with early stopping\n",
        "start_time = time.time()\n",
        "history = resnet10_model.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test), callbacks=[early_stopping])\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = resnet10_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFzEUbnyJ7Oh",
        "outputId": "fc862789-9170-4bef-c7ce-3ddf1b335c43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 52s 19ms/step - loss: 1.5845 - accuracy: 0.4189 - val_loss: 1.5715 - val_accuracy: 0.4491\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.1846 - accuracy: 0.5737 - val_loss: 1.1671 - val_accuracy: 0.5772\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.0350 - accuracy: 0.6287 - val_loss: 1.3665 - val_accuracy: 0.5386\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.9483 - accuracy: 0.6607 - val_loss: 1.0955 - val_accuracy: 0.6067\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8950 - accuracy: 0.6838 - val_loss: 1.4987 - val_accuracy: 0.5491\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8518 - accuracy: 0.7004 - val_loss: 1.3487 - val_accuracy: 0.5760\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8112 - accuracy: 0.7144 - val_loss: 1.2839 - val_accuracy: 0.5964\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7824 - accuracy: 0.7236 - val_loss: 0.9394 - val_accuracy: 0.6759\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7588 - accuracy: 0.7332 - val_loss: 0.8779 - val_accuracy: 0.6909\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7321 - accuracy: 0.7437 - val_loss: 0.8564 - val_accuracy: 0.6963\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7109 - accuracy: 0.7488 - val_loss: 0.9716 - val_accuracy: 0.6755\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.6856 - accuracy: 0.7603 - val_loss: 0.9028 - val_accuracy: 0.6974\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6695 - accuracy: 0.7671 - val_loss: 0.9118 - val_accuracy: 0.7002\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.6519 - accuracy: 0.7738 - val_loss: 1.0927 - val_accuracy: 0.6633\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.6361 - accuracy: 0.7773 - val_loss: 0.9039 - val_accuracy: 0.7028\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.6187 - accuracy: 0.7844 - val_loss: 1.5445 - val_accuracy: 0.5632\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.6065 - accuracy: 0.7878 - val_loss: 0.8044 - val_accuracy: 0.7257\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5928 - accuracy: 0.7950 - val_loss: 1.1907 - val_accuracy: 0.6199\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.5843 - accuracy: 0.7974 - val_loss: 0.7365 - val_accuracy: 0.7475\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.5721 - accuracy: 0.8011 - val_loss: 0.8558 - val_accuracy: 0.7228\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 27s 18ms/step - loss: 0.5595 - accuracy: 0.8068 - val_loss: 0.9310 - val_accuracy: 0.7009\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5469 - accuracy: 0.8108 - val_loss: 0.8094 - val_accuracy: 0.7314\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.5382 - accuracy: 0.8130 - val_loss: 0.8728 - val_accuracy: 0.7111\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.5269 - accuracy: 0.8156 - val_loss: 0.9652 - val_accuracy: 0.7040\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.5241 - accuracy: 0.8180 - val_loss: 1.1302 - val_accuracy: 0.6399\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5145 - accuracy: 0.8202 - val_loss: 0.9869 - val_accuracy: 0.6908\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.5021 - accuracy: 0.8251 - val_loss: 0.8659 - val_accuracy: 0.7211\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.4947 - accuracy: 0.8275 - val_loss: 0.8547 - val_accuracy: 0.7225\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4885 - accuracy: 0.8273 - val_loss: 1.0376 - val_accuracy: 0.6900\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.7365 - accuracy: 0.7475\n",
            "Training Time: 851.56 seconds\n",
            "Training Loss: 0.4885\n",
            "Test Accuracy: 0.7475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2B\n"
      ],
      "metadata": {
        "id": "u6o-0sE4B_es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Define the residual block\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    shortcut = x\n",
        "\n",
        "    # First convolution layer\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Second convolution layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Skip connection\n",
        "    if stride != 1 or shortcut.shape[-1] != filters:\n",
        "        shortcut = layers.Conv2D(filters, 1, strides=stride, kernel_regularizer=tf.keras.regularizers.l2(0.001))(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# Build a smaller ResNet-10 model with different regularization techniques\n",
        "def build_resnet10(regularization=None):\n",
        "    input_shape = (32, 32, 3)\n",
        "    num_classes = 10\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution layer\n",
        "    x = layers.Conv2D(16, 3, padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(10):\n",
        "        x = residual_block(x, 16)\n",
        "\n",
        "    # Global average pooling\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully connected layer with dropout\n",
        "    if regularization == 'dropout':\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Regularization techniques: Weight Decay, Dropout, Batch Normalization\n",
        "regularization_techniques = ['weight_decay', 'dropout', 'batch_normalization']\n",
        "\n",
        "for regularization in regularization_techniques:\n",
        "    # Build and compile the ResNet-10 model with the specified regularization technique\n",
        "    resnet10_model = build_resnet10(regularization)\n",
        "    resnet10_model.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "    # Configure early stopping\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model for 300 epochs with early stopping\n",
        "    start_time = time.time()\n",
        "    history = resnet10_model.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test), callbacks=[early_stopping])\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = resnet10_model.evaluate(x_test, y_test)\n",
        "\n",
        "    # Print results for each regularization technique\n",
        "    print(f\"\\nRegularization Technique: {regularization.capitalize()}\")\n",
        "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "    print(f\"Training Loss: {history.history['loss'][-1]:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO-JLtejCDHE",
        "outputId": "8f449d10-300c-44d6-b1ac-4c4bfe53da61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 45s 21ms/step - loss: 1.7930 - accuracy: 0.4408 - val_loss: 1.7507 - val_accuracy: 0.4575\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.3502 - accuracy: 0.5845 - val_loss: 2.3981 - val_accuracy: 0.3485\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2035 - accuracy: 0.6309 - val_loss: 1.3658 - val_accuracy: 0.5764\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1269 - accuracy: 0.6547 - val_loss: 1.3570 - val_accuracy: 0.5902\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0709 - accuracy: 0.6775 - val_loss: 1.9480 - val_accuracy: 0.4693\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.0403 - accuracy: 0.6906 - val_loss: 1.5889 - val_accuracy: 0.5289\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0082 - accuracy: 0.7040 - val_loss: 1.7610 - val_accuracy: 0.4963\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9820 - accuracy: 0.7142 - val_loss: 1.9036 - val_accuracy: 0.4777\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.9655 - accuracy: 0.7248 - val_loss: 1.3262 - val_accuracy: 0.5963\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.9470 - accuracy: 0.7312 - val_loss: 1.9607 - val_accuracy: 0.5131\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.9305 - accuracy: 0.7379 - val_loss: 1.8729 - val_accuracy: 0.5615\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.9201 - accuracy: 0.7430 - val_loss: 1.2912 - val_accuracy: 0.6298\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.9116 - accuracy: 0.7468 - val_loss: 2.2426 - val_accuracy: 0.4395\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8942 - accuracy: 0.7547 - val_loss: 1.2926 - val_accuracy: 0.5879\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8880 - accuracy: 0.7548 - val_loss: 1.5789 - val_accuracy: 0.5976\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8804 - accuracy: 0.7604 - val_loss: 1.3728 - val_accuracy: 0.6116\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8737 - accuracy: 0.7644 - val_loss: 1.9147 - val_accuracy: 0.5222\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8641 - accuracy: 0.7663 - val_loss: 1.4088 - val_accuracy: 0.6024\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8580 - accuracy: 0.7700 - val_loss: 2.1199 - val_accuracy: 0.4864\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8534 - accuracy: 0.7723 - val_loss: 1.9500 - val_accuracy: 0.4929\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8482 - accuracy: 0.7748 - val_loss: 1.4969 - val_accuracy: 0.5993\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8432 - accuracy: 0.7752 - val_loss: 2.0407 - val_accuracy: 0.5261\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2912 - accuracy: 0.6298\n",
            "\n",
            "Regularization Technique: Weight_decay\n",
            "Training Time: 658.46 seconds\n",
            "Training Loss: 0.8432\n",
            "Test Accuracy: 0.6298\n",
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 41s 19ms/step - loss: 2.1808 - accuracy: 0.2764 - val_loss: 1.7506 - val_accuracy: 0.3932\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.6869 - accuracy: 0.4195 - val_loss: 1.6332 - val_accuracy: 0.4550\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.5604 - accuracy: 0.4691 - val_loss: 1.6001 - val_accuracy: 0.4503\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.4830 - accuracy: 0.5053 - val_loss: 1.7173 - val_accuracy: 0.4104\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.4373 - accuracy: 0.5266 - val_loss: 1.4070 - val_accuracy: 0.5458\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.3997 - accuracy: 0.5412 - val_loss: 1.4607 - val_accuracy: 0.5046\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.3780 - accuracy: 0.5504 - val_loss: 1.4803 - val_accuracy: 0.4970\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.3583 - accuracy: 0.5621 - val_loss: 1.3059 - val_accuracy: 0.5925\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.3385 - accuracy: 0.5726 - val_loss: 1.3670 - val_accuracy: 0.5622\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.3240 - accuracy: 0.5793 - val_loss: 2.1326 - val_accuracy: 0.4067\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.3127 - accuracy: 0.5821 - val_loss: 1.3801 - val_accuracy: 0.5682\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.2981 - accuracy: 0.5894 - val_loss: 1.3629 - val_accuracy: 0.5648\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.3013 - accuracy: 0.5904 - val_loss: 1.5650 - val_accuracy: 0.5248\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.2810 - accuracy: 0.5969 - val_loss: 1.1816 - val_accuracy: 0.6423\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.2771 - accuracy: 0.6016 - val_loss: 1.5865 - val_accuracy: 0.5108\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.2658 - accuracy: 0.6071 - val_loss: 2.0120 - val_accuracy: 0.4345\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2628 - accuracy: 0.6086 - val_loss: 1.6738 - val_accuracy: 0.4539\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.2471 - accuracy: 0.6144 - val_loss: 1.2607 - val_accuracy: 0.6156\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.2417 - accuracy: 0.6194 - val_loss: 1.3898 - val_accuracy: 0.5713\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.2434 - accuracy: 0.6172 - val_loss: 1.3437 - val_accuracy: 0.5729\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2384 - accuracy: 0.6213 - val_loss: 1.5195 - val_accuracy: 0.5446\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2286 - accuracy: 0.6230 - val_loss: 1.2777 - val_accuracy: 0.6029\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2235 - accuracy: 0.6311 - val_loss: 1.1556 - val_accuracy: 0.6536\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.2221 - accuracy: 0.6321 - val_loss: 1.5710 - val_accuracy: 0.5191\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2166 - accuracy: 0.6324 - val_loss: 1.5088 - val_accuracy: 0.5550\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.2040 - accuracy: 0.6388 - val_loss: 1.8919 - val_accuracy: 0.5002\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.2067 - accuracy: 0.6375 - val_loss: 1.2804 - val_accuracy: 0.6116\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.1945 - accuracy: 0.6427 - val_loss: 1.6847 - val_accuracy: 0.5033\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.2047 - accuracy: 0.6366 - val_loss: 2.4753 - val_accuracy: 0.4225\n",
            "Epoch 30/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.1931 - accuracy: 0.6441 - val_loss: 1.7007 - val_accuracy: 0.5339\n",
            "Epoch 31/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.1914 - accuracy: 0.6426 - val_loss: 2.3393 - val_accuracy: 0.4461\n",
            "Epoch 32/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.1891 - accuracy: 0.6476 - val_loss: 2.0595 - val_accuracy: 0.5299\n",
            "Epoch 33/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.1865 - accuracy: 0.6468 - val_loss: 1.5000 - val_accuracy: 0.5510\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1556 - accuracy: 0.6536\n",
            "\n",
            "Regularization Technique: Dropout\n",
            "Training Time: 971.85 seconds\n",
            "Training Loss: 1.1865\n",
            "Test Accuracy: 0.6536\n",
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 41s 19ms/step - loss: 1.7432 - accuracy: 0.4661 - val_loss: 1.6984 - val_accuracy: 0.4572\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.3388 - accuracy: 0.5949 - val_loss: 1.5619 - val_accuracy: 0.4878\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2081 - accuracy: 0.6332 - val_loss: 1.5660 - val_accuracy: 0.5183\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.1320 - accuracy: 0.6588 - val_loss: 2.2639 - val_accuracy: 0.4591\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.0784 - accuracy: 0.6777 - val_loss: 2.7049 - val_accuracy: 0.3974\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.0375 - accuracy: 0.6958 - val_loss: 2.1645 - val_accuracy: 0.5140\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0060 - accuracy: 0.7060 - val_loss: 1.5796 - val_accuracy: 0.5843\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9795 - accuracy: 0.7192 - val_loss: 1.4388 - val_accuracy: 0.5625\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9645 - accuracy: 0.7261 - val_loss: 1.5628 - val_accuracy: 0.5922\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.9485 - accuracy: 0.7294 - val_loss: 1.6406 - val_accuracy: 0.5334\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9287 - accuracy: 0.7396 - val_loss: 1.1549 - val_accuracy: 0.6843\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.9222 - accuracy: 0.7427 - val_loss: 1.1573 - val_accuracy: 0.6598\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.9080 - accuracy: 0.7457 - val_loss: 2.1508 - val_accuracy: 0.4522\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.8993 - accuracy: 0.7538 - val_loss: 1.5529 - val_accuracy: 0.5689\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8975 - accuracy: 0.7508 - val_loss: 1.7591 - val_accuracy: 0.5513\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8859 - accuracy: 0.7572 - val_loss: 1.6881 - val_accuracy: 0.5621\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8810 - accuracy: 0.7607 - val_loss: 1.3481 - val_accuracy: 0.5926\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8710 - accuracy: 0.7630 - val_loss: 1.0668 - val_accuracy: 0.6854\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8687 - accuracy: 0.7652 - val_loss: 1.8527 - val_accuracy: 0.5619\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8629 - accuracy: 0.7684 - val_loss: 1.5129 - val_accuracy: 0.6362\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8560 - accuracy: 0.7710 - val_loss: 1.5893 - val_accuracy: 0.6104\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8549 - accuracy: 0.7703 - val_loss: 1.8501 - val_accuracy: 0.5008\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.8452 - accuracy: 0.7742 - val_loss: 1.3599 - val_accuracy: 0.6264\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8430 - accuracy: 0.7764 - val_loss: 1.2336 - val_accuracy: 0.6625\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8436 - accuracy: 0.7754 - val_loss: 2.3781 - val_accuracy: 0.4835\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8359 - accuracy: 0.7811 - val_loss: 2.8843 - val_accuracy: 0.3578\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8294 - accuracy: 0.7822 - val_loss: 1.0988 - val_accuracy: 0.6987\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8312 - accuracy: 0.7817 - val_loss: 1.1069 - val_accuracy: 0.6949\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0668 - accuracy: 0.6854\n",
            "\n",
            "Regularization Technique: Batch_normalization\n",
            "Training Time: 836.08 seconds\n",
            "Training Loss: 0.8312\n",
            "Test Accuracy: 0.6854\n"
          ]
        }
      ]
    }
  ]
}